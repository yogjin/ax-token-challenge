---
day: 1
title: "LLM 에이전트의 구조를 진단 기반으로 학습하다"
date: "2025-02-20"
tokens: "측정 중"
problems: 3
tools: ["Claude Code"]
---

## 뭘 했는가

LLM 에이전트(Claude Code 같은 도구)가 어떻게 동작하는지 체계적으로 학습했다. 단순히 설명을 읽는 게 아니라, 튜터 프롬프트를 설계해서 Claude에게 내 수준을 진단하고 모르는 것만 가르쳐달라고 했다.

### 해결한 문제들

1. **LLM 에이전트의 내부 구조 이해** — LLM은 텍스트만 출력하고, 런타임이 실제로 도구를 실행한다는 핵심 구조를 파악
2. **컨텍스트 보존 전략** — 토큰 비용 누적 문제와 Auto Memory, PreCompact Hook 등 대응 방법을 학습
3. **Claude Code의 스킬/커맨드 체계** — 공식 문서로 직접 검증해서 커맨드가 스킬로 통합된 사실 확인

## 어떻게 했는가

### 1단계: 진단 프롬프트 설계

"전문 튜터 프롬프트"를 만들어서 Claude에게 줬다. 핵심은 **"먼저 내 수준을 진단하고, 모르는 것만 가르쳐라"**라는 프로세스를 프롬프트에 정의한 것.

프롬프트 구조:
- STEP 1: 질문으로 수준 진단 (8개 영역)
- STEP 2: 아는 것 / 모르는 것 분류
- STEP 3: 최소 학습 세트 도출
- STEP 4: 부족한 개념만 교육

### 2단계: 진단 결과 → 5개 핵심 개념 도출

8개 질문에 답한 결과, 5개 개념이 빈틈으로 나왔다:

1. **LLM은 텍스트 생성기일 뿐** — 도구 호출의 실제 구조
2. **에이전트 루프** — LLM 호출 → 도구 실행 → 결과 주입 → 반복
3. **Few-shot prompting** — 예시를 통한 행동 유도
4. **가드레일 4계층** — system prompt → 권한/승인제 → hooks → 샌드박스
5. **토큰 비용 누적** — 매 루프마다 전체 컨텍스트 재전송

### 3단계: 학습 → 검증

5개 개념을 배운 후 검증 질문 8개를 풀었다. 전부 맞춤.

### 4단계: 공식 문서로 팩트체크

튜터가 "커맨드와 스킬은 별개다"라고 했는데, 공식 문서에는 **"Custom slash commands have been merged into skills"**라고 나와있었다. AI 튜터도 outdated된 정보를 줄 수 있다. 공식 소스 검증은 필수.

## 깨달음

- **진단 → 학습의 효율이 높다.** 이미 아는 걸 다시 듣는 시간을 절약할 수 있다. 프롬프트로 이 프로세스를 설계할 수 있다.
- **"왜?"를 끝까지 따라가야 한다.** "런타임이 실행한다"에서 멈추지 않고 "런타임이 뭔데?" → "그것도 시스템콜 아니냐?" → "그럼 미리 정의된 도구만 쓰는 거냐?"로 이어가야 진짜 이해가 된다.
- **AI 튜터의 답변을 그대로 믿으면 안 된다.** 공식 문서로 검증하는 습관이 필요하다. 실제로 오늘 틀린 정보를 잡아냈다.
- **이론을 바로 "내 상황"에 대입해봐야 한다.** 벡터 DB를 배우고 "어떻게 써야 할지 감이 안 온다"고 솔직하게 말한 것이 실용적인 답을 얻는 데 도움이 됐다.
